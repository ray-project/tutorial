{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Learning how to use Tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning hyperparameters is often the most expensive part of the machine learning workflow. \n",
    "\n",
    "Tune is built to address this, demonstrating an efficient and scalable solution for this pain point.\n",
    "\n",
    "This tutorial will walk you through the following process:\n",
    "\n",
    "1. Integrating Tune into your workflow\n",
    "2. Setting a stopping criteria\n",
    "3. Getting the best model and analyzing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.integration.keras import TuneReporterCallback\n",
    "from ray.tune.examples.utils import get_iris_data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first take a look at the distribution of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "true_data = iris['data']\n",
    "true_label = iris['target']\n",
    "names = iris['target_names']\n",
    "feature_names = iris['feature_names']\n",
    "\n",
    "def plot_data(X, y):\n",
    "    # Visualize the data sets\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for target, target_name in enumerate(names):\n",
    "        X_plot = X[y == target]\n",
    "        plt.plot(X_plot[:, 0], X_plot[:, 1], linestyle='none', marker='o', label=target_name)\n",
    "    plt.xlabel(feature_names[0])\n",
    "    plt.ylabel(feature_names[1])\n",
    "    plt.axis('equal')\n",
    "    plt.legend();\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for target, target_name in enumerate(names):\n",
    "        X_plot = X[y == target]\n",
    "        plt.plot(X_plot[:, 2], X_plot[:, 3], linestyle='none', marker='o', label=target_name)\n",
    "    plt.xlabel(feature_names[2])\n",
    "    plt.ylabel(feature_names[3])\n",
    "    plt.axis('equal')\n",
    "    plt.legend();\n",
    "    \n",
    "plot_data(true_data, true_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define a function that will train a model to classify this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_iris():\n",
    "    train_x, train_y, test_x, test_y = get_iris_data()\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(2, input_shape=(4,), activation='relu', name='fc1'))\n",
    "    model.add(Dense(2, activation='relu', name='fc2'))\n",
    "    model.add(Dense(3, activation='softmax', name='output'))\n",
    "    optimizer = SGD(lr=0.1)\n",
    "    model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # This saves the top model\n",
    "    checkpoint_callback = ModelCheckpoint(\"model.h5\", monitor='val_loss', save_best_only=True, period=3)\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        train_x, train_y, \n",
    "        validation_data=(test_x, test_y),\n",
    "        verbose=0, batch_size=5, epochs=50, callbacks=[checkpoint_callback])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_on_iris()\n",
    "train_x, train_y, test_x, test_y = get_iris_data()\n",
    "model.evaluate(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate with Tune\n",
    "\n",
    "Now, let's use Tune to optimize a model that learns to classify Iris. This will take three steps:\n",
    "\n",
    "1. Designate the hyperparameter space.\n",
    "\n",
    "\n",
    "2. Set a callback to report results back to Tune\n",
    "3. Increase the number of samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_iris(config):\n",
    "    train_x, train_y, test_x, test_y = get_iris_data()\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(config[\"dense_1\"], input_shape=(4,), activation='relu', name='fc1'))\n",
    "    model.add(Dense(config[\"dense_2\"], activation='relu', name='fc2'))\n",
    "    model.add(Dense(3, activation='softmax', name='output'))\n",
    "    optimizer = SGD(lr=config[\"lr\"])\n",
    "    model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    checkpoint_callback = ModelCheckpoint(\"model.h5\", monitor='val_loss', save_best_only=True, period=3)\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        train_x, train_y, \n",
    "        validation_data=(test_x, test_y),\n",
    "        verbose=0, \n",
    "        batch_size=5, \n",
    "        epochs=50, \n",
    "        callbacks=[checkpoint_callback, TuneReporterCallback(freq=\"epoch\")])\n",
    "    \n",
    "\n",
    "results = tune.run(\n",
    "    tune_iris, \n",
    "    config={\"lr\": 0.1, \"dense_1\": 1, \"dense_2\": 0.1},\n",
    "    num_samples=1,\n",
    "    return_trials=False)\n",
    "\n",
    "assert len(results.trials) == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate best trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = results.dataframe()\n",
    "\n",
    "logdir = results.get_best_logdir(\"keras_info:val_loss\", mode=\"min\")\n",
    "\n",
    "# import keras.models\n",
    "from keras.models import load_model\n",
    "model = load_model(logdir + \"/model.h5\")\n",
    "\n",
    "train_data, train_labels, _, _ = get_iris_data()\n",
    "plot_data(train_data, train_labels.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.evaluate(train_data, train_labels)\n",
    "print(\"Loss is {}\".format(res[0]))\n",
    "print(\"Accuracy is {}\".format(res[1]))\n",
    "predicted_label = model.predict(train_data)\n",
    "plot_data(train_data, predicted_label.argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Tensorboard for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {logdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tensorboard --logdir {logdir}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
