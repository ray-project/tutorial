{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL Exercise 5 - Training and Serving a Policy with Ray\n",
    "\n",
    "**GOAL:** The goal of this exercise is to show how to train a policy with Ray and deploy it using an actor in a fun, interactive way.\n",
    "\n",
    "We will train an agent to play Pong, and then we will play Pong against the policy that we trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import gym\n",
    "import pong_py  # If this line fails, you need to do \"pip install utilities/pong_py\".\n",
    "import ray\n",
    "\n",
    "from ray.rllib.agents.ppo import PPOAgent, DEFAULT_CONFIG\n",
    "from ray.tune.registry import register_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init(num_cpus=36, ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE:** Run the cell below to instantiate an agent that can be trained using Proximal Policy Optimization (PPO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DEFAULT_CONFIG.copy()\n",
    "# Consider using more workers to speed up the rollouts.\n",
    "config['num_workers'] = 8\n",
    "config['gamma'] = 0.99\n",
    "config['sgd_stepsize'] = 5e-3\n",
    "config['kl_coeff'] = 0.1\n",
    "config['num_sgd_iter'] = 20\n",
    "config['timesteps_per_batch'] = 8196 * 4\n",
    "config['sgd_batchsize'] = 8196\n",
    "config['observation_filter'] = 'NoFilter'\n",
    "config['model']['fcnet_hiddens'] = [32, 32]\n",
    "\n",
    "def env_creator(env_config):\n",
    "    import pong_py\n",
    "    return pong_py.PongJSEnv()\n",
    "\n",
    "register_env('pong_env', env_creator)\n",
    "\n",
    "agent = PPOAgent(env='pong_env', config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Policy\n",
    "\n",
    "Train the `PPOAgent` for some number of iterations.\n",
    "\n",
    "**EXERCISE:** You will need to experiment with the number of iterations as well as with the configuration to get the agent to learn something reasonable. Training may take around 30 or so iterations.\n",
    "\n",
    "**NOTE:** You may want to skip this box for now and try playing against the untrained policy. After you've done that, you can return to this box, train the policy more, and serve the updated policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    result = agent.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the agent manually by calling `agent.compute_action` and see the rewards you get are consistent with the rewards printed during the training procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = env_creator({})\n",
    "\n",
    "for _ in range(20):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    cumulative_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action = agent.compute_action(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        cumulative_reward += reward\n",
    "\n",
    "    print(cumulative_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoint the agent so that the relevant model can be saved and served by the actor webserver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = agent.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play Against the Policy\n",
    "\n",
    "Below, we've provided an actor that runs a very simple webserver to serve the policy. The webserver will respond to POST requests coming from the javascript game and will serve actions used to power the AI opponent.\n",
    "\n",
    "To play against the policy you trained, start the webserver by running the cell below. Instructions will be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cgi\n",
    "from http.server import BaseHTTPRequestHandler, HTTPServer\n",
    "import json\n",
    "import requests\n",
    "import socketserver\n",
    "import subprocess\n",
    "import threading\n",
    "\n",
    "\n",
    "# Check that we haven't already started the server.\n",
    "try:\n",
    "    server\n",
    "except:\n",
    "    pass\n",
    "else:\n",
    "    raise Exception('The policy server has already been created, so we are not creating another one.')\n",
    "\n",
    "\n",
    "# Check that the required port isn't already in use.\n",
    "try:\n",
    "    requests.get('http://localhost:3000')\n",
    "except:\n",
    "    pass\n",
    "else:\n",
    "    raise Exception('The port 3000 is still in use (perhaps from a previous run of this notebook. '\n",
    "                    'You will need to kill that process before proceeding, e.g., by running '\n",
    "                    '\"subprocess.call([\\'ray\\', \\'stop\\'])\" in a new cell and restarting this notebook.')\n",
    "\n",
    "def make_handler_class(agent):\n",
    "    \"\"\"This function is used to define a custom handler using the policy.\"\"\"\n",
    "\n",
    "    class PolicyHandler(BaseHTTPRequestHandler):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            BaseHTTPRequestHandler.__init__(self, *args, **kwargs)\n",
    "            \n",
    "        def end_headers(self):\n",
    "            self.send_header('Access-Control-Allow-Origin', '*')\n",
    "            self.send_header('Access-Control-Allow-Methods', '*')\n",
    "            self.send_header('Access-Control-Allow-Headers', 'Content-Type')\n",
    "            BaseHTTPRequestHandler.end_headers(self)\n",
    "        \n",
    "        def do_OPTIONS(self):\n",
    "            self.send_response(200, 'ok')\n",
    "            self.end_headers()\n",
    "\n",
    "        def do_POST(self):\n",
    "            \"\"\"This method receives the state of the game and returns an action.\"\"\"\n",
    "            length = int(self.headers.get_all('content-length')[0])\n",
    "            post_body = cgi.parse_qs(self.rfile.read(length), keep_blank_values=1)\n",
    "            features = json.loads(list(post_body.keys())[0])['input']\n",
    "\n",
    "            self.send_response(200)\n",
    "            self.send_header('Content-type', 'json')\n",
    "            self.end_headers()\n",
    "\n",
    "            # NOTE: This line is where we compute the action using the policy.\n",
    "            action = int(agent.compute_action(features))\n",
    "        \n",
    "            self.wfile.write(json.dumps({'output': action}).encode('ascii'))\n",
    "\n",
    "    return PolicyHandler\n",
    "\n",
    "@ray.remote\n",
    "class PolicyServer(object):\n",
    "    def __init__(self, port, config, checkpoint_path):\n",
    "        self.port = port\n",
    "\n",
    "        config['num_workers'] = 0\n",
    "        self.agent = PPOAgent(env='pong_env', config=config)\n",
    "        self.agent.restore(checkpoint_path)\n",
    "\n",
    "        self.HandlerClass = make_handler_class(self.agent)\n",
    "\n",
    "    def start_server(self):\n",
    "        # run web server, do this in a separate thread\n",
    "        def run_server(port):\n",
    "            httpd = HTTPServer(('', port), self.HandlerClass)\n",
    "            httpd.serve_forever()\n",
    "\n",
    "        self.server_thread = threading.Thread(target=run_server,\n",
    "                                              args=(self.port,))\n",
    "\n",
    "        print('Starting server.')\n",
    "        self.server_thread.start()\n",
    "\n",
    "    def update_policy(self, checkpoint_path):\n",
    "        # update policy\n",
    "        self.agent.restore(checkpoint_path)\n",
    "\n",
    "\n",
    "print('Starting the server, this will take some time.')\n",
    "server = PolicyServer.remote(3000, config, checkpoint_path)\n",
    "ray.get(server.start_server.remote())\n",
    "print('The server has started.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE:** Run the cell below to print the URL of the Pong game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "try:\n",
    "    # Figure out the public IP address if we are on an EC2 instance.\n",
    "    public_ip = subprocess.check_output(['curl', '-m', '5', 'http://169.254.169.254/latest/meta-data/public-ipv4']).decode('ascii')\n",
    "    address = 'http://{}/pong'.format(public_ip)\n",
    "except subprocess.CalledProcessError:\n",
    "    address = 'http://localhost:8888/notebooks/utilities/javascript-pong/static/index.html'\n",
    "\n",
    "display(HTML('To play against your policy, go to <a href=\"{0}\" target=\"_blank\">{0}</a> and PRESS \"1\".'.format(address)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Update the policy\n",
    "\n",
    "To update the policy, leave the webserver running (you do not need to start a new webserver), and run the box below.\n",
    "\n",
    "This will checkpoint the current policy and load the updated policy on the webserver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint the current policy.\n",
    "checkpoint_path = agent.save()\n",
    "\n",
    "# Serve the updated policy.\n",
    "ray.get(server.update_policy.remote(checkpoint_path))\n",
    "\n",
    "print('The policy has been updated. You can continue playing at the same URL as before.')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
