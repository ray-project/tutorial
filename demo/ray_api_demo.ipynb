{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ray API Demo: Parallel Training\n",
    "\n",
    "Demo created by [Peter Schafhalter](https://github.com/pschafhalter/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training function\n",
    "\n",
    "Trains a classifier with a hyperparameter.\n",
    "\n",
    "Technical details:\n",
    "- The classifier is a multi-layer perceptron.\n",
    "- The hyperamater (alpha) is the regularization parameter.\n",
    "- The value of alpha affects the [bias-variance tradeoff](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff), which impacts whether the model underfits or overfits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Import the scikit-learn machine learning library\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def train(alpha, train_x, test_x, train_y, test_y):\n",
    "    # Instantiate a model with the given value of alpha\n",
    "    classifier = MLPClassifier(alpha=alpha, max_iter=10000)\n",
    "    # Train the model on the training data\n",
    "    classifier.fit(train_x, train_y)\n",
    "    # Evaluate the model on the test data and return the model's accuracy score\n",
    "    predicted_y = classifier.predict(test_x)\n",
    "    return accuracy_score(test_y, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training with Hyperparameters\n",
    "\n",
    "- Try different values for alpha to train best model.\n",
    "- Without parallelizing this is slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Imports for profiling and visualization\n",
    "from IPython.core.display import HTML\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "from utils import ray_get_with_progress_bar\n",
    "\n",
    "# Imports for generating the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "# Generate the dataset\n",
    "x, y = make_moons(noise=0.8, random_state=0)\n",
    "\n",
    "# Set hyperparameters\n",
    "trials = [10**-x for x in range(16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Train with different values for alpha\n",
    "results = []\n",
    "start = time.time()\n",
    "for alpha in tqdm.tqdm(trials):\n",
    "    results.append(train(alpha, *train_test_split(x, y)))\n",
    "serial_time = time.time() - start\n",
    "\n",
    "# Print results\n",
    "HTML(f\"<h3>Best accuracy: {max(results):.2f}</h3><h3>Total time: {serial_time:.2f} seconds</h3>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallel Training with Ray\n",
    "\n",
    "1. Import and set up ray with `ray.init()`\n",
    "2. Add the `ray.remote` decorator to `train`\n",
    "3. Replace calls to `train(...)` with `train.remote(...)`\n",
    "4. Get the resulting python objects with `results = ray.get(results)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "HTML(f\"\"\"<h3>Started Ray locally with:<h3>\n",
    "<h3>{ray.cluster_resources()[\"CPU\"] : .0f} CPUs</h3>\n",
    "<h3>{ray.cluster_resources()[\"memory\"]} GB of memory available</h3>\n",
    "<h3>{ray.cluster_resources()[\"object_store_memory\"]} GB of object store memory</h3>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def train(alpha, train_x, test_x, train_y, test_y):\n",
    "    classifier = MLPClassifier(alpha=alpha, max_iter=10000)\n",
    "    classifier.fit(train_x, train_y)\n",
    "    predicted_y = classifier.predict(test_x)\n",
    "    return accuracy_score(test_y, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Train with different values for alpha\n",
    "results = []\n",
    "start = time.time()\n",
    "for alpha in trials:\n",
    "    # Call train with train.remote(...)\n",
    "    results.append(train.remote(alpha, *train_test_split(x, y)))\n",
    "\n",
    "# Get results\n",
    "# results = ray.get(results)   # This works just like the result below, but without progress bar\n",
    "results = ray_get_with_progress_bar(results)\n",
    "\n",
    "parallel_time = time.time() - start\n",
    "\n",
    "# Print results\n",
    "HTML(f\"\"\"<h3>Best accuracy: {max(results):.2f}</h3>\n",
    "<h3>Total time: {parallel_time:.2f} seconds ({serial_time / parallel_time : .2f}x faster)</h3>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallel Training with Ray on a Cluster\n",
    "\n",
    "1. Launch a Ray cluster on AWS with `ray up cluster_config.yaml`\n",
    "2. SSH into head node\n",
    "3. Replace `ray.init()` with `ray.init(redis_address=\"...\")`\n",
    "\n",
    "The Ray Autoscalar can add and remove nodes as the workload changes. Currently, it integrates with AWS, GCP, Kubernetes, and private clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Connect to cluster\n",
    "CLUSTER_ADDRESS = None # Set this to run on cluster\n",
    "ray.shutdown()\n",
    "ray.init(redis_address=CLUSTER_ADDRESS, include_webui=True)\n",
    "\n",
    "url = ray.get_webui_url()  # Override this in case of SSH forwarding from the cluster\n",
    "HTML(f\"\"\"<h3>Connected to Ray cluster with:<h3>\n",
    "<h3>{ray.cluster_resources()[\"CPU\"] : .0f} CPUs</h3>\n",
    "<h3>{ray.cluster_resources()[\"memory\"]} GB of memory available</h3>\n",
    "<h3>{ray.cluster_resources()[\"object_store_memory\"]} GB of object store memory</h3>\n",
    "<br>\n",
    "<a href='{url}'>Dashboard</a>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Train with different values for alpha\n",
    "results = []\n",
    "start = time.time()\n",
    "for alpha in trials:\n",
    "    # Call train with train.remote(...)\n",
    "    results.append(train.remote(alpha, *train_test_split(x, y)))\n",
    "\n",
    "# Get results\n",
    "# results = ray.get(results)   # This works just like the result below, but without progress bar\n",
    "results = ray_get_with_progress_bar(results)\n",
    "\n",
    "cluster_time = time.time() - start\n",
    "\n",
    "# Print results\n",
    "HTML(f\"\"\"<h3>Best accuracy: {max(results):.2f}</h3>\n",
    "<h3>Total time: {cluster_time:.2f} seconds ({serial_time / parallel_time : .2f}x faster)</h3>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Train with different values for alpha\n",
    "cluster_trials = [i for i in range(100)]\n",
    "results = []\n",
    "start = time.time()\n",
    "for alpha in cluster_trials:\n",
    "    # Call train with train.remote(...)\n",
    "    results.append(train.remote(alpha, *train_test_split(x, y)))\n",
    "\n",
    "# Get results\n",
    "# results = ray.get(results)   # This works just like the result below, but without progress bar\n",
    "results = ray_get_with_progress_bar(results)\n",
    "\n",
    "cluster_large_workload_time = time.time() - start\n",
    "\n",
    "# Print results\n",
    "HTML(f\"\"\"<h3>Best accuracy: {max(results):.2f}</h3>\n",
    "<h3>Total time: {cluster_large_workload_time:.2f} seconds ({cluster_large_workload_time / serial_time : .2f}x slower)</h3>\n",
    "<h3>Total trials: {len(cluster_trials)}\\t({round(len(cluster_trials) / len(trials))}x more trials)\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "HTML(f\"\"\"<h3>Time without Ray:\\t{serial_time:.2f} seconds</h3>\n",
    "<h3>Time with Ray:\\t{parallel_time:.2f} seconds ({serial_time / parallel_time :.2f}x faster)</h3>\n",
    "<h3>Time with Ray on Cluster:\\t{cluster_time:.2f} seconds ({serial_time / cluster_time :.2f}x faster)</h3>\n",
    "<h3>Ran {round(len(cluster_trials) / len(trials))}x more trials on cluster in {cluster_large_workload_time:.2f} seconds ({cluster_large_workload_time / serial_time : .2f}x slower)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note: speedup doesn't exactly scale with cores due to overhead.\n",
    "\n",
    "Speedup tends to become linear as the number of tasks increases, or tasks become longer."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
